2023-12-20 13:05:52,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 13:05:52,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 13:05:52,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 13:05:52,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 13:05:54,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:54,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:54,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:54,872:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:55,064:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:55,065:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:55,254:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:55,254:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:55,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:55,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:55,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:55,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:55,813:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:55,814:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:55,996:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:55,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:56,168:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:56,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:56,347:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:56,347:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:56,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:56,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:56,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:56,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:56,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:56,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:57,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:57,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:05:57,824:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:05:57,936:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:05:58,023:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:05:58,102:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:05:58,987:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:05:59,107:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:05:59,217:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:05:59,328:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:05:59,608:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:05:59,624:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:05:59,639:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:05:59,655:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:00,144:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:00,194:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:00,253:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:00,301:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:00,487:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:00,503:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:00,526:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:00,536:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:01,426:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:01,553:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:01,660:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:01,756:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:01,913:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:01,921:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:01,929:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:01,941:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,088:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,104:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,119:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,135:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,289:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,300:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,308:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,319:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,455:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,471:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,474:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,487:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,662:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,674:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,678:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,694:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,854:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,854:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,874:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:02,885:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,082:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,102:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,116:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,132:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,288:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,288:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,304:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,323:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,512:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,520:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,536:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,541:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,705:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,721:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,736:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,736:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,941:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,957:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,969:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:03,977:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:04,123:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:04,138:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:04,154:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:06:04,154:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:07:30,488:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:30,553:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:30,709:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:30,819:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:07:31,035:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:07:31,425:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:31,859:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:31,906:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:32,870:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:32,917:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:33,040:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:33,136:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:07:33,325:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:07:33,632:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:34,000:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:34,046:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:34,226:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:34,295:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:34,421:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:34,516:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:07:34,704:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:07:35,033:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:35,467:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:35,523:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:35,689:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:35,738:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:35,879:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:35,962:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:07:36,147:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:07:36,473:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:36,895:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:36,953:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:37,122:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:37,180:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:37,319:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:37,413:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:07:37,615:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:07:37,931:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:38,311:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:07:38,385:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:18:52,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:52,205:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:52,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:52,427:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:52,615:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:52,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:52,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:52,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:52,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:52,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:53,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:53,159:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:53,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:53,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:53,514:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:53,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:53,703:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:53,703:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:53,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:53,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:54,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:54,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:54,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:54,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:54,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:54,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:54,659:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:54,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:18:55,249:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:55,339:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:55,410:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:55,504:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:56,335:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:56,451:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:56,587:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:56,693:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:56,894:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:56,909:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:56,925:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:56,953:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:57,427:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:57,490:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:57,554:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:57,625:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:57,807:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:57,823:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:57,839:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:57,859:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:58,921:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,031:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,157:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,257:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,424:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,424:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,439:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,457:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,616:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,624:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,630:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,656:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,808:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,808:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,823:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,839:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,975:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,975:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,991:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:18:59,991:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,164:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,172:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,188:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,188:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,359:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,372:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,388:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,388:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,583:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,619:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,635:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,644:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,804:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,820:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,820:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:00,835:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,003:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,013:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,027:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,027:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,190:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,205:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,213:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,229:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,374:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,390:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,406:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,406:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,574:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,590:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,590:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:01,610:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:19:04,849:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:05,052:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:05,303:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:05,352:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:19:05,519:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:19:05,724:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:05,833:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:05,958:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:06,319:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:06,507:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:06,744:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:06,813:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:19:06,987:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:19:07,183:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:07,287:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:07,412:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:07,459:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:07,672:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:07,916:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:07,996:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:19:08,148:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:19:08,362:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:08,473:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:08,606:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:08,654:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:08,858:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:09,092:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:09,154:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:19:09,329:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:19:09,527:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:09,629:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:09,756:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:09,812:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:10,017:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:10,253:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:10,357:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:19:10,517:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:19:10,732:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:10,822:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:10,962:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:19:11,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:19:11,486:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:19:11,564:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:19:11,564:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:19:11,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:19:11,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:19:11,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:19:11,747:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:19:11,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:19:11,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:19:11,933:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:19:11,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:19:12,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:19:12,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:19:12,190:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:19:12,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:01,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:01,074:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:01,264:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:01,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:01,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:01,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:01,629:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:01,629:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:01,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:01,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:02,010:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:02,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:02,202:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:02,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:02,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:02,391:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:02,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:02,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:02,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:02,759:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:02,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:02,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:03,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:03,151:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:03,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:03,382:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:03,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:03,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:20:04,184:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:04,261:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:04,344:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:04,496:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:05,367:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:05,478:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:05,589:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:05,704:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:05,911:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:05,927:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:05,944:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:05,950:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:06,455:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:06,512:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:06,558:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:06,620:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:06,858:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:06,865:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:06,880:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:06,895:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:08,016:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:08,162:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:08,326:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:08,465:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:08,659:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:08,667:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:08,686:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:08,701:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:08,888:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:08,901:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:08,917:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:08,933:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,118:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,124:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,134:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,158:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,342:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,357:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,374:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,388:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,595:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,610:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,629:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,647:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,836:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,858:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,865:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:09,894:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,118:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,141:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,149:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,165:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,373:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,391:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,407:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,423:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,598:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,614:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,630:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,652:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,819:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,824:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,843:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:10,858:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:11,040:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:11,061:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:11,071:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:11,073:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:11,236:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:11,257:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:11,268:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:11,286:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:20:17,168:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:20:17,336:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:17,444:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:17,594:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:20:18,009:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:18,445:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:18,711:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:18,786:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:18,853:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:20:19,008:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:19,120:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:19,255:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:20:19,952:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:20,225:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:20,450:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:20,519:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:20,606:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:20:20,768:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:20,869:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:21,000:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:20:21,358:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:21,713:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:21,929:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:21,996:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:22,051:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:20:22,205:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:22,302:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:22,423:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:20:22,802:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:23,117:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:23,326:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:23,388:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:23,435:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:20:23,598:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:23,722:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:23,839:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:20:24,176:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:24,521:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:24,775:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:20:24,824:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:03,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:03,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:03,465:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:03,465:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:03,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:03,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:03,827:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:03,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:04,004:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:04,004:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:04,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:04,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:04,361:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:04,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:04,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:04,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:04,750:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:04,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:04,927:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:04,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:05,118:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:05,118:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:05,311:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:05,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:05,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:05,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:05,749:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:05,749:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:06,394:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:06,476:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:06,553:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:06,634:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:07,526:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:07,632:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:07,752:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:07,875:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:08,086:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:08,106:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:08,155:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:08,170:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:08,635:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:08,687:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:08,746:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:08,795:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:08,987:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:09,004:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:09,020:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:09,036:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:10,183:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:10,328:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:10,470:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:10,610:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:10,791:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:10,801:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:10,817:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:10,831:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:10,990:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,006:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,017:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,025:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,176:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,190:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,190:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,207:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,348:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,357:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,364:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,380:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,534:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,548:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,565:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,566:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,728:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,752:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,763:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,774:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,968:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:11,984:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,000:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,015:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,173:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,184:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,196:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,210:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,373:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,392:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,400:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,406:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,554:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,573:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,591:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,607:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,754:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,771:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,788:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,791:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,972:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,983:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:12,992:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:13,006:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:21:16,329:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:16,537:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:21:16,676:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:16,853:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:21:16,972:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:17,272:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:17,370:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:17,420:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:17,776:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:17,965:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:21:18,127:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:18,286:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:21:18,403:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:18,680:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:18,836:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:18,883:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:18,936:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:19,148:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:21:19,289:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:19,452:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:21:19,569:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:19,857:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:20,020:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:20,080:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:20,130:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:20,323:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:21:20,469:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:20,652:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:21:20,769:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:21,090:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:21,228:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:21,283:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:21,327:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:21,518:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:21:21,683:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:21,857:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:21:21,972:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:22,270:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:22,436:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:22,485:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:21:22,635:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:22,635:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:22,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:22,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:22,813:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:22,813:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:22,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:22,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:22,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:22,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:23,066:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:23,066:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:23,193:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:23,193:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:23,286:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:21:23,286:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:09,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:09,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:09,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:09,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:10,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:10,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:10,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:10,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:10,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:10,421:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:10,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:10,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:10,791:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:10,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:10,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:10,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:11,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:11,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:11,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:11,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:11,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:11,549:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:11,748:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:11,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:12,004:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:12,004:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:12,193:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:12,193:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:12,797:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:12,891:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:12,986:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:13,065:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:14,021:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:14,123:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:14,245:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:14,358:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:14,567:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:14,582:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:14,598:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:14,622:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:15,118:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:15,163:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:15,228:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:15,285:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:15,463:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:15,486:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:15,493:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:15,527:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:16,719:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:16,862:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,005:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,125:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,289:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,299:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,304:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,320:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,476:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,487:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,494:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,510:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,662:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,662:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,682:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,695:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,844:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,853:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,860:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:17,876:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,030:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,053:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,062:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,076:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,241:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,270:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,288:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,303:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,504:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,514:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,528:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,544:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,704:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,719:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,729:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,736:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,885:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,903:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,919:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:18,935:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:19,091:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:19,103:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:19,109:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:19,124:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:19,279:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:19,293:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:19,303:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:19,311:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:19,479:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:19,482:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:19,496:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:19,511:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:23:22,834:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:22,957:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:23,165:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:23,240:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:23,639:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:23,800:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:23,846:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:23,941:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:24,276:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:24,400:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:24,604:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:24,678:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:25,115:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:25,318:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:25,366:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:25,466:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:25,507:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:25,638:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:25,852:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:25,938:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:26,332:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:26,499:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:26,549:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:26,640:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:26,677:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:26,807:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:26,997:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:27,082:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:27,452:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:27,684:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:27,730:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:27,824:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:27,872:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:27,997:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:28,207:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:28,298:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:28,677:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:28,897:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:28,947:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:29,043:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:29,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,314:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,398:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,801:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,911:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:23:29,920:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:23:30,070:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:30,181:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:30,448:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:30,663:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:30,663:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:30,663:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:30,676:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:30,676:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:30,756:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:30,763:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:30,851:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:30,851:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:30,851:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:30,851:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:30,851:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:30,948:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:30,949:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:31,039:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:23:31,151:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:31,276:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:31,373:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:31,596:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:31,799:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:31,814:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:31,815:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:31,815:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:31,815:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:31,923:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:31,925:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:31,925:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:31,925:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:31,925:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:32,034:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:32,034:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,034:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,047:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:32,048:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:32,147:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:32,147:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,156:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,156:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:32,156:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:32,252:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:23:32,312:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,329:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,346:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,371:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,387:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,412:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,429:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:32,429:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,434:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,437:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:32,437:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:32,452:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:32,452:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,452:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,452:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:32,452:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:32,466:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:32,466:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,479:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,479:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:32,479:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:32,495:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:32,498:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,500:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,503:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:32,504:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:32,584:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:23:32,597:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,612:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,629:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,646:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,662:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,675:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,691:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:32,691:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,691:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,691:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:32,691:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:32,705:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:32,705:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,705:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,705:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:32,705:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:32,720:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:32,728:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,730:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,731:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:32,731:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:32,738:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:32,745:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,746:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,746:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:32,746:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:32,826:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:23:32,878:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,906:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,924:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:32,985:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:33,000:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:33,000:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:33,016:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:33,016:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:33,016:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:33,016:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:33,016:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:33,033:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:33,033:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:33,049:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:33,049:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:33,049:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:33,064:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:33,064:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:33,152:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:23:33,287:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:33,428:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:33,555:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:33,848:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,150:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:34,150:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,150:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,150:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:34,150:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:34,307:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:34,307:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,310:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,311:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:34,311:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:34,431:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:34,431:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,431:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,431:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:34,447:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:34,573:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:34,575:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,662:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:23:34,677:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:23:34,695:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,707:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:23:34,711:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,727:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:23:34,727:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,744:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:23:34,761:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:23:34,778:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:23:34,778:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,798:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:23:34,798:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,805:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:23:34,818:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,820:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,820:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:34,820:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:34,838:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:23:34,840:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,850:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:23:34,850:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,944:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:23:34,964:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,976:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:34,990:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,037:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,053:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,078:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:35,078:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,078:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,085:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:35,087:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:35,096:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:35,096:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,096:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,096:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:35,096:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:35,129:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:35,129:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,133:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,133:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:35,133:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:35,149:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:35,149:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,228:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:23:35,259:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,291:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,372:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:35,372:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,372:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,372:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:35,372:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:35,395:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:35,395:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,395:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,401:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:35,403:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:35,403:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:35,417:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,417:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,417:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:35,417:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:35,433:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:35,433:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,519:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:23:35,577:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,642:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,702:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,834:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,978:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:35,997:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,997:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:35,997:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:35,997:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:36,055:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:36,055:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,068:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,068:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:36,068:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:36,140:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:36,140:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,140:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,147:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:36,147:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:36,196:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:36,205:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,291:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:23:36,372:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:23:36,372:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,387:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:23:36,387:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,402:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:23:36,402:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,418:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:23:36,434:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:23:36,451:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:23:36,451:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,466:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:23:36,466:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,466:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,481:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:36,481:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:36,494:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:23:36,494:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,497:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,497:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:36,497:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:36,513:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:23:36,514:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,516:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,516:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:36,516:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:36,531:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:23:36,531:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,615:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:23:36,670:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,688:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,709:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,765:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,781:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:36,783:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,797:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:36,797:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,797:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,797:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:36,797:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:36,816:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:36,816:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,829:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:36,829:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,916:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:23:36,932:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:36,952:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,009:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,036:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:37,036:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,036:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,051:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:37,052:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:37,052:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:37,052:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,069:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,069:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:37,069:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:37,083:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:37,085:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,085:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,085:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:37,085:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:37,101:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:37,101:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,101:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,101:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:37,101:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:37,182:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:23:37,254:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 13:23:37,262:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,276:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 13:23:37,287:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,297:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 13:23:37,317:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,327:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 13:23:37,342:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,353:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 13:23:37,360:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,360:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 13:23:37,376:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,393:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:37,398:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,399:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,399:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:37,399:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:37,409:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:37,409:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,409:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,409:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:37,409:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:37,426:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:37,426:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,426:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,438:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:37,438:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:37,443:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:23:37,453:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,454:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:37,454:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:23:37,454:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:23:39,175:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:39,276:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:39,880:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:23:40,372:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:40,429:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:40,632:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:40,632:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2023-12-20 13:23:40,756:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:40,836:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:41,043:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:41,137:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:41,302:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\neighbors\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  return self._fit(X, y)

2023-12-20 13:23:41,365:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:41,430:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:41,479:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_ridge.py:1182: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:41,541:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:41,591:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:41,640:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:41,773:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:41,773:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2023-12-20 13:23:41,899:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:41,947:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:42,158:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:42,259:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:42,364:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\neighbors\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  return self._fit(X, y)

2023-12-20 13:23:42,427:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:42,473:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:42,519:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_ridge.py:1182: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:42,567:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:42,614:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:42,659:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:42,812:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:42,812:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2023-12-20 13:23:42,913:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:42,969:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:43,191:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:43,284:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:43,394:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\neighbors\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  return self._fit(X, y)

2023-12-20 13:23:43,461:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:43,523:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:43,572:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_ridge.py:1182: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:43,617:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:43,665:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:43,707:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:43,846:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:43,846:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2023-12-20 13:23:44,018:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:44,062:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:44,282:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:44,374:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:44,516:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\neighbors\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  return self._fit(X, y)

2023-12-20 13:23:44,563:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:44,607:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:44,656:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_ridge.py:1182: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:44,705:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:44,751:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:44,811:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:44,931:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:44,931:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2023-12-20 13:23:45,047:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:45,089:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:23:45,300:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:45,395:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:45,537:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\neighbors\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  return self._fit(X, y)

2023-12-20 13:23:45,585:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:45,632:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:45,678:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_ridge.py:1182: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:23:45,710:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:26:46,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 13:26:46,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 13:26:46,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 13:26:46,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 13:26:47,052:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:47,053:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:47,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:47,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:47,389:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:47,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:47,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:47,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:47,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:47,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:47,899:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:47,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:48,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:48,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:48,178:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:48,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:48,306:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:48,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:48,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:48,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:48,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:48,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:48,711:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:48,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:48,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:48,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:49,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:49,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:26:49,461:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:49,525:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:49,588:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:49,652:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:50,282:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:50,359:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:50,438:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:50,520:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:50,697:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:50,703:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:50,719:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:50,736:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:51,084:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:51,145:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:51,191:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:51,225:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:51,385:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:51,402:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:51,418:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:51,418:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:52,297:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:52,402:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:52,501:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:52,612:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:52,765:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:52,768:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:52,787:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:52,797:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:52,952:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:52,968:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:52,979:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:52,992:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,141:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,154:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,168:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,186:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,325:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,339:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,339:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,356:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,502:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,518:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,531:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,535:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,699:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,701:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,718:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,732:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,903:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,917:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,928:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:53,928:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,086:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,100:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,118:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,128:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,283:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,295:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,295:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,317:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,473:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,473:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,487:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,505:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,650:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,667:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,667:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,686:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,833:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,850:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,863:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:54,867:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 13:26:58,121:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:26:58,173:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:26:58,302:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:26:58,431:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:26:58,666:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:26:58,747:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:26:59,046:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:26:59,210:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:26:59,433:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:26:59,476:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:26:59,587:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:26:59,731:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:26:59,953:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:00,061:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:00,345:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:00,522:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:00,585:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:00,637:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:00,754:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:00,895:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:01,148:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:01,237:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:01,563:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:01,730:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:01,780:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:01,815:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:01,936:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:02,080:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:02,328:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:02,438:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:02,735:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:02,903:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:02,952:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:02,998:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:03,122:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:03,267:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:03,499:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:03,596:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:03,871:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:04,043:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:04,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,535:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,535:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,622:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,622:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,839:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,839:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,920:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 13:27:04,936:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:27:05,121:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:05,426:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:05,604:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:05,604:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:05,610:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:05,610:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:05,610:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:05,699:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:05,701:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:05,784:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:05,784:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:05,784:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:05,784:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:05,784:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:05,872:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:05,874:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:05,960:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:27:06,093:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:06,202:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:06,450:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:06,554:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:06,660:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:06,760:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:06,760:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:06,769:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:06,771:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:06,771:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:06,864:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:06,864:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:06,978:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:06,978:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:06,978:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:06,978:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:06,978:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:07,077:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:07,077:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,164:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:27:07,183:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,203:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,224:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,248:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,266:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,282:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,302:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:07,302:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,302:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,314:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:07,314:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:07,330:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:07,330:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,330:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,330:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:07,330:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:07,346:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:07,353:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,354:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,354:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:07,354:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:07,360:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:07,360:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,376:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,379:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:07,379:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:07,457:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:27:07,474:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,492:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,509:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,527:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,537:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,560:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,570:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:07,576:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,576:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,578:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:07,578:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:07,587:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:07,587:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,595:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,597:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:07,597:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:07,609:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:07,611:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,613:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,613:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:07,613:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:07,627:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:07,627:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,627:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,627:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:07,627:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:07,713:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:27:07,729:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,773:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,793:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,815:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,847:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:07,855:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,855:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,859:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:07,861:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:07,872:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:07,872:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,880:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,880:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:07,880:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:07,896:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:07,896:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,912:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:07,920:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,920:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:07,920:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:07,920:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:08,004:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:27:08,136:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:08,278:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:08,550:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:08,676:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:08,809:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:08,944:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:08,947:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:08,947:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:08,947:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:08,947:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:09,075:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:09,075:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,209:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:09,213:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,216:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,216:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:09,216:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:09,343:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:09,343:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,427:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:27:09,441:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:27:09,441:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,462:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:27:09,489:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:27:09,494:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,507:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:27:09,507:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,521:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:27:09,521:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,542:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:27:09,560:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:27:09,560:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,560:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,560:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:09,560:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:09,575:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:27:09,575:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,592:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:27:09,592:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,606:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 13:27:09,616:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,695:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:27:09,713:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,738:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,752:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,775:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,792:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,806:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,826:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:09,826:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,832:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,832:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:09,832:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:09,847:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:09,847:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,847:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,847:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:09,847:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:09,866:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:09,866:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,881:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:09,881:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:09,967:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:27:10,056:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,073:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,088:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:10,088:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,092:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,092:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:10,092:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:10,109:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:10,109:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,125:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:10,125:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,125:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,125:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:10,125:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:10,142:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:10,142:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,231:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:27:10,342:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,525:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,584:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,646:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:10,646:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,646:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,646:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:10,646:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:10,707:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:10,709:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,767:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:10,797:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,798:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,799:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:10,801:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:10,851:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:10,858:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:10,941:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:27:10,953:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:27:10,976:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:27:10,994:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:27:10,997:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,012:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:27:11,030:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:27:11,030:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,042:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:27:11,042:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,068:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:27:11,068:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,068:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,072:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:11,072:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:11,072:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:27:11,087:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,091:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:27:11,103:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,107:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,108:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:11,109:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:11,121:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 13:27:11,121:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,207:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:27:11,223:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,250:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,263:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,295:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,328:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:11,329:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,329:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,329:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:11,329:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:11,345:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:11,345:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,360:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:11,360:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,377:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:11,377:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,465:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:27:11,481:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,547:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,593:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:11,593:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,593:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,593:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:11,593:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:11,609:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:11,619:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,624:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:11,624:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,624:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,638:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:11,640:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:11,641:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:11,654:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,732:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 13:27:11,742:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 13:27:11,748:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,764:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 13:27:11,773:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,780:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 13:27:11,780:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,797:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 13:27:11,808:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,814:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 13:27:11,827:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,827:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 13:27:11,845:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,861:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:11,861:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,861:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,861:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:11,861:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:11,876:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:11,876:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,891:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:11,891:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,909:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 13:27:11,909:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,909:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:11,922:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 13:27:11,922:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 13:27:13,392:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:13,500:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:13,849:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:14,139:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:14,241:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:14,336:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:14,445:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:14,538:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 13:27:14,824:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:14,824:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2023-12-20 13:27:15,016:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:15,057:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:15,210:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\neighbors\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  return self._fit(X, y)

2023-12-20 13:27:15,250:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:15,306:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:15,346:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:15,473:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:15,556:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:15,614:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:15,757:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_ridge.py:1182: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:15,811:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:15,855:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:15,855:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2023-12-20 13:27:16,051:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:16,094:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:16,250:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\neighbors\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  return self._fit(X, y)

2023-12-20 13:27:16,298:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:16,344:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:16,377:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:16,512:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:16,598:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:16,653:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:16,813:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_ridge.py:1182: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:16,855:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:16,901:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:16,901:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2023-12-20 13:27:17,062:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:17,114:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:17,254:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\neighbors\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  return self._fit(X, y)

2023-12-20 13:27:17,298:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:17,355:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:17,394:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:17,521:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:17,608:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:17,655:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:17,815:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_ridge.py:1182: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:17,854:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:17,904:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:17,904:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2023-12-20 13:27:18,087:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:18,128:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:18,278:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\neighbors\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  return self._fit(X, y)

2023-12-20 13:27:18,315:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:18,380:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:18,421:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:18,539:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:18,632:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:18,670:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:18,840:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_ridge.py:1182: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:18,891:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:18,939:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:18,972:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2023-12-20 13:27:19,123:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:19,160:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:19,320:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\neighbors\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  return self._fit(X, y)

2023-12-20 13:27:19,368:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:19,403:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:19,412:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 13:27:19,462:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 13:27:19,587:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:19,670:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:19,720:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:19,887:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_ridge.py:1182: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 13:27:19,920:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:14,477:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 20:46:14,477:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 20:46:14,477:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 20:46:14,477:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 20:46:16,499:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:16,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:16,669:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:16,669:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:16,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:16,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:17,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:17,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:17,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:17,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:17,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:17,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:17,674:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:17,674:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:17,861:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:17,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:18,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:18,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:18,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:18,223:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:18,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:18,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:18,569:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:18,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:18,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:18,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:19,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:19,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:19,751:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:19,840:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:19,937:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:20,023:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:20,909:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:21,016:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:21,139:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:21,253:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:21,507:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:21,521:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:21,535:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:21,549:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:21,951:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:21,996:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:22,046:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:22,110:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:22,324:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:22,336:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:22,343:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:22,359:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:23,242:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:23,353:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:23,472:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:23,583:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:23,752:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:23,760:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:23,770:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:23,784:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:23,979:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:23,986:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:23,997:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,015:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,175:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,189:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,205:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,214:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,356:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,366:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,368:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,382:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,572:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,586:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,603:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,616:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,815:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,835:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,844:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:24,852:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,042:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,059:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,074:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,091:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,249:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,249:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,262:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,279:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,468:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,479:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,479:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,503:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,648:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,662:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,678:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,678:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,839:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,851:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,855:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:25,869:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:26,064:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:26,069:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:26,081:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:26,098:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:29,435:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:29,600:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:29,900:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:30,323:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:30,392:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:30,477:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:30,684:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:30,734:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:31,045:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:31,172:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:31,442:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:31,799:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:31,853:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:31,947:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:32,151:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:32,201:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:32,259:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:32,372:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:32,685:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:33,015:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:33,103:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:33,198:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:33,408:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:33,454:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:33,509:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:33,627:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:33,906:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:34,259:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:34,365:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:34,469:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:34,671:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:34,720:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:34,767:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:34,879:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:35,115:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:35,461:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:35,531:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:35,655:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:35,849:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:35,897:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:36,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,390:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,481:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,481:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:36,842:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 20:46:37,206:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:37,302:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:37,488:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:37,488:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:37,596:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:37,596:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:37,596:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:37,596:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:37,596:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:37,673:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:37,673:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:37,781:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:37,783:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:37,869:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 20:46:38,067:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:38,319:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:38,423:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:38,532:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:38,633:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:38,633:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:38,633:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:38,645:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:38,645:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:38,743:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:38,743:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:38,756:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:38,756:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:38,756:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:38,868:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:38,868:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:38,868:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:38,868:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:38,868:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:38,973:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:38,986:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:38,986:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:38,986:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:38,986:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:39,079:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 20:46:39,096:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,115:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,141:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,161:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,172:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,204:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,224:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:39,226:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,228:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,229:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:39,230:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:39,247:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:39,249:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,250:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,252:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:39,253:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:39,269:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:39,269:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,269:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,269:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:39,269:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:39,283:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:39,283:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,283:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,301:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:39,301:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:39,385:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 20:46:39,401:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,417:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,433:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,450:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,467:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,476:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,490:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:39,490:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,490:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,490:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:39,490:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:39,511:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:39,511:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,511:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,522:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:39,522:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:39,533:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:39,533:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,538:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,541:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:39,541:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:39,554:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:39,554:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,554:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,554:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:39,554:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:39,644:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 20:46:39,738:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,754:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,778:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,802:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,817:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:39,817:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,817:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,817:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:39,817:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:39,833:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:39,833:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,852:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:39,860:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,860:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,860:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:39,860:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:39,877:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:39,877:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:39,968:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 20:46:40,373:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:40,508:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:40,663:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:40,803:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:40,935:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:40,935:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:40,944:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:40,947:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:40,947:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:41,073:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:41,073:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,073:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,087:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:41,087:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:41,228:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:41,228:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,235:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,235:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:41,235:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:41,371:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:41,371:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,371:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,371:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:41,371:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:41,458:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 20:46:41,510:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 20:46:41,527:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 20:46:41,543:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 20:46:41,553:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,569:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 20:46:41,588:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 20:46:41,593:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,605:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 20:46:41,605:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,627:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 20:46:41,633:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,636:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,637:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:41,637:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:41,661:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 20:46:41,661:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,680:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 20:46:41,683:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,696:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 20:46:41,696:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,783:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 20:46:41,799:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,811:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,836:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,855:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,871:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,889:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,905:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:41,905:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,927:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:41,927:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,927:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,927:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:41,927:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:41,951:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:41,952:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,954:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:41,954:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:41,954:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:41,969:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:41,969:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:42,053:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 20:46:42,122:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:42,143:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:42,173:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:42,173:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:42,192:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:42,192:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:42,192:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:42,192:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:42,192:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:42,209:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:42,209:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:42,227:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:42,234:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:42,316:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 20:46:42,546:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:42,608:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:42,698:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:42,759:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:42,761:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:42,809:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:42,822:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:42,822:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:42,827:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:42,827:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:42,887:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:42,888:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:42,950:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:42,950:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,042:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 20:46:43,094:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 20:46:43,113:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 20:46:43,126:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 20:46:43,135:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,149:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 20:46:43,149:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,168:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 20:46:43,168:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,183:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 20:46:43,183:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,198:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 20:46:43,198:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,209:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,210:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:43,210:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:43,215:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 20:46:43,215:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,238:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 20:46:43,242:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,245:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 20:46:43,245:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,343:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 20:46:43,390:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,427:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,445:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,461:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:43,461:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,461:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,469:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:43,469:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:43,474:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:43,485:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,500:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:43,500:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,519:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:43,521:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,606:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 20:46:43,638:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,677:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,705:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,725:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,738:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:43,738:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,738:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,738:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:43,738:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:43,758:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:43,759:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,759:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,759:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:43,759:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:43,769:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:43,769:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,769:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,769:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:43,769:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:43,785:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:43,785:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,799:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,799:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:43,799:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:43,877:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\model_selection\_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2023-12-20 20:46:43,935:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 20:46:43,939:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,954:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 20:46:43,954:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,975:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 20:46:43,986:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:43,992:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 20:46:44,004:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:44,004:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 20:46:44,020:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:44,035:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-20 20:46:44,042:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:44,052:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:44,052:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:44,052:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:44,052:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:44,052:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:44,068:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:44,068:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:44,068:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:44,082:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:44,083:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:44,092:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:44,092:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:44,098:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:44,098:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:44,098:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:44,113:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-20 20:46:44,115:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:44,115:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:44,115:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-20 20:46:44,115:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-20 20:46:45,706:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:45,815:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:45,911:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:45,998:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:46,493:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:46,589:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 20:46:46,975:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:47,163:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:47,163:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2023-12-20 20:46:47,273:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:47,313:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:47,362:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:47,533:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:47,667:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:47,755:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\neighbors\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  return self._fit(X, y)

2023-12-20 20:46:47,858:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:48,005:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:48,072:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_ridge.py:1182: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:48,110:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:48,157:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:48,300:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:48,300:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2023-12-20 20:46:48,452:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:48,516:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:48,564:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:48,708:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:48,849:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:48,897:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\neighbors\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  return self._fit(X, y)

2023-12-20 20:46:49,023:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:49,122:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:49,175:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_ridge.py:1182: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:49,210:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:49,256:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:49,398:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:49,413:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2023-12-20 20:46:49,523:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:49,576:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:49,622:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:49,778:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:49,913:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:49,958:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\neighbors\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  return self._fit(X, y)

2023-12-20 20:46:50,047:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:50,132:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:50,198:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_ridge.py:1182: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:50,246:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:50,295:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:50,442:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:50,442:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2023-12-20 20:46:50,597:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:50,662:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:50,712:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:50,888:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:50,997:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:51,053:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\neighbors\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  return self._fit(X, y)

2023-12-20 20:46:51,163:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:51,258:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:51,320:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_ridge.py:1182: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:51,354:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:51,420:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:51,588:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:51,588:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\preprocessing\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2023-12-20 20:46:51,707:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:51,753:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:51,802:WARNING:C:/Users/14357/github/research/stressor/inst/python/refit_class.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  refit_mlm_new_model = r.refit_mlm_temp.fit(r.refit_mlm_X, r.refit_mlm_y)

2023-12-20 20:46:51,977:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:52,103:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:52,153:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\neighbors\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
  return self._fit(X, y)

2023-12-20 20:46:52,248:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:52,338:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:52,374:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_ridge.py:1182: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:52,436:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-12-20 20:46:53,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:53,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:53,309:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:53,309:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:53,465:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:53,465:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:53,604:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:53,604:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:53,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:53,720:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:53,865:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:53,865:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:54,006:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:54,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:54,145:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:54,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:54,286:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:54,287:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:54,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:54,427:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:54,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:54,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:54,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:54,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:54,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:54,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:55,073:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:55,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:46:55,560:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:55,621:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:55,687:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:55,753:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:56,497:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:56,585:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:56,674:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:56,752:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:56,939:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:56,954:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:56,968:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:56,985:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:57,356:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:57,401:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:57,445:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:57,485:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:57,655:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:57,675:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:57,691:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:57,704:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:58,612:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:58,722:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:58,839:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:58,961:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,113:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,136:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,150:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,162:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,317:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,332:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,350:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,361:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,518:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,518:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,534:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,550:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,695:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,705:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,717:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,723:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,884:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,902:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,914:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:46:59,917:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,105:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,117:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,123:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,136:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,317:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,333:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,353:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,393:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,562:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,562:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,584:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,591:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,750:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,760:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,780:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,791:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,950:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,963:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,965:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:00,983:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:01,149:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:01,166:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:01,176:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:01,176:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:01,345:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:01,357:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:01,368:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:01,382:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:47:58,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:47:58,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:47:58,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:47:58,824:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:47:58,993:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:47:58,993:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:47:59,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:47:59,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:47:59,422:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:47:59,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:47:59,613:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:47:59,613:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:47:59,802:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:47:59,802:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:47:59,981:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:47:59,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:48:00,165:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:48:00,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:48:00,348:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:48:00,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:48:00,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:48:00,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:48:00,721:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:48:00,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:48:00,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:48:00,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:48:01,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:48:01,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:48:01,739:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:01,842:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:01,916:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:02,012:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:02,863:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:02,967:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:03,084:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:03,190:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:03,392:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:03,406:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:03,424:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:03,439:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:03,937:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:04,004:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:04,057:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:04,115:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:04,357:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:04,377:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:04,389:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:04,403:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:05,564:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:05,737:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:05,886:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,041:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,231:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,241:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,264:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,271:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,462:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,475:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,495:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,505:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,689:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,707:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,730:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,737:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,914:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,928:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,946:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:06,959:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:07,212:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:07,236:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:07,244:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:07,260:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:07,447:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:07,463:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:07,480:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:07,496:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:07,720:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:07,739:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:07,763:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:07,768:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:07,968:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:07,989:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,011:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,026:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,201:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,212:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,225:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,241:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,395:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,412:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,422:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,439:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,595:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,616:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,628:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,639:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,795:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,807:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,824:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:48:08,836:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:10,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 20:50:10,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 20:50:10,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 20:50:10,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-20 20:50:10,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:10,843:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:11,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:11,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:11,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:11,183:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:11,371:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:11,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:11,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:11,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:11,726:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:11,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:11,909:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:11,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:12,084:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:12,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:12,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:12,236:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:12,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:12,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:12,552:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:12,590:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:12,708:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:12,708:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:12,889:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:12,889:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:13,041:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:13,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 20:50:13,537:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:13,600:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:13,662:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:13,710:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:14,351:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:14,441:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:14,537:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:14,615:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:14,830:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:14,841:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:14,857:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:14,873:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:15,223:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:15,270:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:15,310:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:15,365:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:15,532:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:15,543:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:15,543:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:15,560:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:16,434:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:16,561:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:16,684:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:16,804:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:16,975:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:16,988:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:16,994:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,004:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,158:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,170:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,185:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,194:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,342:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,354:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,369:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,369:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,521:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,537:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,537:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,568:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,719:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,735:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,735:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,751:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,903:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,918:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,934:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:17,950:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,132:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,147:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,164:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,179:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,333:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,349:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,366:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,366:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,532:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,548:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,564:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,591:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,753:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,753:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,769:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,784:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,936:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,936:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,952:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:18,967:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:19,119:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:19,119:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:19,134:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 20:50:19,150:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:25,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:25,914:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:26,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:26,108:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:26,290:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:26,290:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:26,469:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:26,469:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:26,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:26,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:26,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:26,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:27,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:27,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:27,194:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:27,194:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:27,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:27,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:27,548:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:27,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:27,736:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:27,736:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:27,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:27,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:28,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:28,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:28,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:28,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:28,923:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:29,015:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:29,110:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:29,183:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:30,048:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:30,163:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:30,326:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:30,437:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:30,642:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:30,658:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:30,677:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:30,705:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:31,225:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:31,288:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:31,350:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:31,429:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:31,642:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:31,657:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:31,673:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:31,689:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:32,839:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:32,966:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:33,124:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:33,245:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:33,426:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:33,426:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:33,442:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:33,465:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:33,626:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:33,626:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:33,641:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:33,657:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:33,826:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:33,826:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:33,842:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:33,857:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:33,995:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,011:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,011:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,026:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,183:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,194:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,194:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,209:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,377:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,393:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,393:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,410:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,608:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,624:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,624:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,640:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,864:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,880:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,889:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:34,898:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,042:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,065:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,073:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,084:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,242:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,242:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,258:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,282:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,482:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,490:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,497:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,506:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,658:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,673:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,686:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:35,689:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:00:39,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:39,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:39,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:39,258:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:39,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:39,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:39,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:39,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:39,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:39,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:39,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:39,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:39,762:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:39,762:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:39,859:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:00:39,859:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:30,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:30,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:30,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:30,240:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:30,437:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:30,437:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:30,603:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:30,603:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:30,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:30,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:30,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:30,977:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:31,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:31,151:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:31,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:31,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:31,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:31,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:31,698:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:31,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:31,887:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:31,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:32,075:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:32,075:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:32,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:32,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:32,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:32,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:33,105:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:33,183:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:33,261:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:33,340:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:34,189:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:34,299:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:34,434:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:34,535:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:34,740:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:34,756:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:34,777:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:34,788:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:35,267:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:35,315:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:35,378:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:35,458:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:35,641:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:35,656:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:35,672:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:35,688:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:36,848:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:36,995:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:37,138:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:37,280:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:37,480:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:37,492:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:37,508:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:37,525:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:37,723:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:37,740:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:37,755:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:37,771:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,019:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,030:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,044:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,059:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,220:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,236:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,251:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,266:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,455:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,482:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,503:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,519:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,732:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,740:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,756:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,772:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,971:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:38,987:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,003:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,020:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,171:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,188:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,188:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,204:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,370:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,386:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,402:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,412:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,574:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,590:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,590:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,605:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,772:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,788:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,788:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,804:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,970:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:39,986:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:40,002:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:40,012:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-12-20 21:01:43,510:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:43,510:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:43,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:43,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:43,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:43,699:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:43,791:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:43,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:43,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:43,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:43,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:43,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:44,073:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:44,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:44,152:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:01:44,152:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:10,259:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:10,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:10,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:10,369:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:10,494:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:10,494:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:10,620:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:10,629:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:10,740:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:10,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:10,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:10,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:11,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:11,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:11,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:02:11,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:14,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:14,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:14,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:14,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:14,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:14,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:14,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:14,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:15,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:15,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:15,153:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:15,161:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:15,348:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:15,348:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:15,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:15,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-20 21:03:18,000:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 21:03:19,458:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 21:03:21,640:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 21:03:21,668:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 21:03:21,683:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 21:03:21,719:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 21:03:21,731:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 21:03:21,765:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 21:03:21,791:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 21:03:21,810:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 21:03:21,821:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 21:03:21,838:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 21:03:21,857:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-20 21:03:22,514:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 21:03:23,681:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 21:03:23,713:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 21:03:23,728:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 21:03:23,746:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 21:03:23,767:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 21:03:23,792:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 21:03:23,807:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 21:03:23,823:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 21:03:23,840:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 21:03:23,868:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-20 21:03:24,098:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-20 21:03:24,281:WARNING:C:\Users\14357\DOCUME~1\VIRTUA~1\STRESS~3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

