---
title: "stressor"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{stressor}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This package is designed to allow the user to use multiple machine learning 
methods by calling simple commands for data exploration. To get started, this 
package requires that you have <a href = https://www.python.org/downloads/release/python-3810/>Python 3.8.10</a>
installed on your computer. Visit the link before and follow the instructions to
install Python. 

Once installed, we will add it to our work space like other packages.
```{r setup}
library(stressor)
```

## Data Generation

In this section we will show an example of generating data where are assumed 
model is linear with a epsilon that we choose. We will generate 500 entries to a
linear model that has five variables with equal weights and y-intercept of 0. 
We will then choose a response standard deviation of 1.
```{r}
set.seed(43421)
lm_data <- data_gen_lm(500, weight_vec = rep(1, 5), y_int = 0, resp_sd = 1)
head(lm_data)
```

## Machine Learning Model Workflow

In this section we will demonstrate the workflow to use this package to explore
the machine learning models(mlm) that are accessible through the PyCaret module
in python. First we need to create a virtual environment for the PyCaret module
to exist in. The first time you run this code will take a bit as it needs to 
install the necessary modules into the virtual environment. Once installed the 
following message will be shown after you execute the code indicating that you
are now using the virtual environment. See the <a href=#troubleshoot>
troubleshoot</a> section if other errors appear.
```{r}
create_virtualenv()
```

Next we need create all the mlm by running this command. This may take a moment
the first time you run as the PyCaret module needs to be imported. Then
depending on your data size it may take a moment to fit the data. Note you will
be prompted
```{r eval=FALSE}
mlm_lm <- mlm_regressor(Y ~ ., lm_data)
```

```{r echo=FALSE}
mlm_lm <- mlm_regressor(Y ~ ., lm_data, silent = TRUE)
top_rmse <- min(mlm_lm$pred_accuracy$rmse)
```

Now we can look at the initial predictive accuracy of the various models by
```{r}
mlm_lm$pred_accuracy
```

In comparison we can fit this data using the `lm()` function and check the 
initial predictive accuracy with a simple test data.
```{r}
test_index <- sample(1:nrow(lm_data), 50)
test <- lm_data[test_index, ]
train <- lm_data[-test_index, ]
lm_test <- lm(Y ~ ., train)
lm_rmse <- sqrt(sum((lm_test$residuals)^2)/ nrow(train))
```

As we look at this initial result we see that there are some comparable models 
to the rmse of generated from `lm()` which is `r lm_rmse` compared to 
`r top_rmse`. We see that the analytical model is still performs better than the
models that were fitted, however, this can be by chance of the random subsetting
of the test and train set. A better practice will be performing a cross 
validation either Leave One Out (LOO) or standard cross validation. In this case
we will demonstrate the use of standard cross validation as the rest stem from
specifying parameters inside the `cv()` function.
```{r}
mlm_cv <- cv(mlm_lm, lm_data, n_folds = 10, k_mult = NULL)
rmse(mlm_cv, lm_data$Y)
```


<div id="troubleshoot">
## Troubleshooting
</div>
