---
title: "stressor"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{stressor}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This package is designed to allow the user to use multiple machine learning 
methods by calling simple commands for data exploration. Python has a library
called PyCaret which is a pipeline process for fitting multiple models with a 
few lines of codes. This package uses the `reticulate` package to allow python
to be ran in R. Therefore giving the same tools that exist in python now in 
your session of R. One of the strengths of R is exploration, this package gives 
you the chance to explore the machine learning models side by side.

To get started, this package requires that you have Python 3.8.10</a>
installed on your computer. To install Python, please follow the instructions provide at:
<p style="text-align:center;"> <a href = https://www.python.org/downloads/release/python-3810/> https://www.python.org/downloads/release/python-3810/</a> </p>

Once Python is installed, you can install stressor currently from github with
hopes to being able to install it from CRAN. To use the python features of this
package the package does not need to be attached with the `library` statement. 
For convenience, we will attach it.
```{r setup}
library(stressor)
```

## Data Generation

It is convenient when testing new function or algorithms to be able to generate
toy data sets. With these toy data sets we can choose what the distribution of
the parameters as well as what the underlying model of the toy data set is. With
this we can also choose the distribution of the error term.

In this section, we will show an example of generating linear data with an 
epsilon and intercept that we choose. We will generate 500 observations from a
linear model with five independent variables and a y-intercept of zero.
Observations are simulated from this model assuming that the residuals follow a
normal distribution with a mean of zero and a standard deviation of one. With 
respect to the variables chosen, each variable is sampled from a normal
distribution with mean zero and standard deviation of one. For this case, we 
choose to let the coefficients on each term to be one as we wanted each 
independent variable to be equally weighted. When we created the response
variable, Y, it is the sum of each independent variable plus an epsilon term
that is sampled from a standard normal distribution.
```{r}
set.seed(43421)
lm_data <- data_gen_lm(500, weight_vec = rep(1, 5), y_int = 0, resp_sd = 1)
head(lm_data)
```

## Machine Learning Model Workflow

In this section, we will demonstrate a typical workflow using the functions of
this package to explore the machine learning models (mlm) that are accessible 
through the PyCaret module in python. First, we need to create a virtual 
environment for the PyCaret module to exist in. The first time you run this code
it will take some time (~ 5 min) as it needs to install the necessary modules 
into the virtual environment. PyCaret recommends that its library be used in a 
virtual environment. A virtual environment is a separate partition of the python
that can have a specific python version installed, as well as other python
libraries. This way all the tools needed are contained in a convenient way
without messing with the main version of python installed.

Once installed the following message will be shown after you execute the code 
indicating that you are now using the virtual environment. See the <a 
href=#troubleshoot>troubleshoot</a> section if other errors appear. You do not
need to install a new environment for each R session, one time and you are done.
The only time you will need to install a new environment is if you decide to 
delete a stressor environment and need to instantiate a new one. These 
environments are stored inside the python module on your computer. 
```{r}
create_virtualenv()
```

Next, we need to create all the mlm by running this command. This may take a 
moment (< 3 min) the first time you run it as the PyCaret module needs to be 
imported. Then depending on your data size it may take a moment to fit the data.
Note you will be prompted to press the enter key. This enter key press is for 
PyCaret to setup the variables for the various models and get the data ready for
fitting.
```{r eval=FALSE}
mlm_lm <- mlm_regressor(Y ~ ., lm_data)
```

```{r echo=FALSE, message=TRUE}
mlm_lm <- mlm_regressor(Y ~ ., lm_data, silent = TRUE)
acc <- mlm_lm$pred_accuracy
top_rmse <- min(acc$rmse)
name_rmse <- acc$Model[acc$rmse == top_rmse]
```

Now, we can look at the initial predictive Root Mean Squared Error (RMSE) of the various models. Currently RMSE is the only method supported at this time. The 
`mlm_lm` object is a list object where the first element is a list of all the
models that were fitted. In that if I were to pass these models back to PyCaret
they can be refitted or used again for predictions. The second element is a data frame of the initial RMSE values and the corresponding models. If you want to
specify the models that are fitted you can change the `fit_models` parameter to
a character vector specifying the models to be fitted.
```{r}
mlm_lm$pred_accuracy
```

In comparison we can fit this data using the `lm()` function and check the 
initial predictive accuracy with a simple test data.
```{r}
test_index <- sample(1:nrow(lm_data), 50)
test <- lm_data[test_index, ]
train <- lm_data[-test_index, ]
lm_test <- lm(Y ~ ., train)
lm_rmse <- sqrt(sum((lm_test$residuals)^2)/ nrow(train))
```

As we look at this initial result, we see that there are some comparable models 
to the RMSE generated from `lm()` (which is `r trunc(lm_rmse * 100)/100` 
compared to `r trunc(top_rmse * 100)/100` fitted by `r name_rmse`). We see that 
the analytical model still outperforms the models that were fitted. However, it 
is not clear from this output alone whether the better performance observed from
the lm model is statistically significant. A better practice will be performing 
a cross validation. In this case we will demonstrate the use of cross validation
as the other forms of cross-validation stem from specifying parameters inside 
the `cv()` function, i.e. Leave-One-Out (LOO) and clustered cross validation.

In this code we are fitting the mlm to the `lm_data` using a 10 fold cross
validation as well as using the `lm_test` object to also perform a 10 fold
cross validation.
```{r}
mlm_cv <- cv(mlm_lm, lm_data, n_folds = 10)
lm_cv <- cv(lm_test, lm_data, n_folds = 10)
rmse(mlm_cv, lm_data$Y)
rmse(lm_cv, lm_data$Y)
```
We can see that the linear model fitted by `lm()` is still better than the mlm.

## Real Data Example
We want to show how are functions apply to a real data example. We can simulate data but it is never quite like real observed data. The purpose of this data set is to show its use on the functions in this package, specifically the cross validation.
We will be using the Boston Housing Data from the `mlbench` package. There are 
two versions of this data, that has been updated. We will also be
ignoring spatial autocorrelation.  
```{r eval=FALSE}
data(boston)
mlm_boston <- mlm_regressor(cmedv ~ ., boston)
mlm_boston$pred_accuracy
```

```{r echo=FALSE}
data(boston)
mlm_boston_pred_accuracy <- stressor::mlm_vignette_boston_pred
mlm_boston_pred_accuracy
```
Observe the initial rmse values for the Boston data set. Now compare these
to the cross validated rmse values.
```{r eval=FALSE}
mlm_boston_cv <- cv(mlm_boston, boston, n_folds = 10)
mlm_boston_rmse <- rmse(mlm_boston_cv, boston$cmedv)
mlm_boston_rmse
```
```{r echo=FALSE}
data(mlm_vignette_boston_cv)
mlm_boston_rmse <- rmse(mlm_vignette_boston_cv, boston$cmedv)
mlm_boston_rmse
```

Now, compare to the clustered cross validation:
```{r eval=FALSE}
mlm_boston_clust_cv <- cv(mlm_boston, boston, n_folds = 10, k_mult = 5)
mlm_boston_clust_rmse <- rmse(mlm_boston_clust_cv, boston$cmedv)
mlm_boston_clust_rmse
```
```{r echo=FALSE}
data(mlm_vignette_boston_cluster)
boston_clust_rmse <- rmse(mlm_vignette_boston_cluster, boston$cmedv)
boston_clust_rmse
```

<div id="troubleshoot">
## Troubleshooting
When instantiating the virtual environment, you may receive some errors or 
warnings. `reticulate` has done a nice job with the error handling of 
instantiating the virtual environment. If you receive a warning and the warning
states that it attaches to the same virtual environment that the message prints
out, you can ignore that warning. The error from `reticulate` will prompt you to 
restart your R session.
</div>
